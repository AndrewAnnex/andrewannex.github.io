@article{Paar2023,
author = {Paar, Gerhard and Ortner, Thomas and Tate, Christian and Deen, Robert G. and Abercrombie, Parker and Vona, Marsette and Proton, Jon and Bechtold, Andreas and Calef, Fred and Barnes, Robert and Koeberl, Christian and Herkenhoff, Ken and Hausrath, Elisabeth M. and Traxler, Christoph and Caballo, Piluca and Annex, Andrew M. and Gupta, Sanjeev and Bell III, James F. and Maki, Justin},
title = {Three-Dimensional Data Preparation and Immersive Mission-Spanning Visualization and Analysis of Mars 2020 Mastcam-Z Stereo Image Sequences},
journal = {Earth and Space Science},
volume = {10},
number = {3},
pages = {e2022EA002532},
keywords = {Mars exploration, visualization, Mars 2020, Mastcam-Z},
doi = {https://doi.org/10.1029/2022EA002532},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2022EA002532},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2022EA002532},
note = {e2022EA002532 2022EA002532},
abstract = {Abstract The Mars 2020 Mastcam-Z stereo camera investigation enables the generation of three dimension (3D) data products needed to visualize and analyze rocks, outcrops, and other geological and aeolian features. The Planetary Robotics Vision Processing framework “PRoViP” as well as the Instrument Data System on a tactical—sol-by-sol—timeframe generate 3D vision products, such as panoramas, distance maps, and textured meshes. Structure-from-motion used by the Advanced Science Targeting Toolkit for Robotic Operations (ASTTRO) “Landform” tool and long baseline stereo pipelines add to the 3D vision products' suite on various scales. Data fusion with textured meshes from satellite imagery and 3D data analysis and interpretation of the resulting large 3D data sets is realized by visualization assets like the Planetary Robotics Vision 3D Viewer PRo3D, the 3D Geographical Information System GIS CAMP (Campaign Analysis Mapping and Planning tool), the ASTTRO 3D data presentation and targeting tool, and the Mastcam-Z planning tool Viewpoint. The pipelines' workflows and the user-oriented features of the visualization assets, shared across the Mars 2020 mission, are reported. The individual role and interplay, complements and synergies of the individual frameworks are explained. Emphasis is laid on publicly available 3D vision data products and tools. A representative set of scientific use cases from planetary geology, aeolian activity, soil analysis and impact science illustrates the scientific workflow, and public data deployment modes are briefly outlined, demonstrating that 3D vision processing and visualization is an essential mission-wide asset to solve important planetary science questions such as prevailing wind direction, soil composition, or geologic origin.},
year = {2023}
}

